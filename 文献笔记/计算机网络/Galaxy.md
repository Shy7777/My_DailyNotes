## A Resource-Efficient Collaborative Edge  AI System for In-situ Transformer Inference  一种资源高效的协同边缘人工智能系统，用于现场 Transformer 推理

Q：什么是面向边缘设备
A：**面向边缘设备**指技术、系统或应用专门针对靠近用户终端的边缘节点（如智能音箱、物联网传感器、边缘网关、小型计算设备等）设计，适配其**算力有限、内存紧张、网络带宽不稳定**的特点，核心满足低延迟、数据本地化（隐私保护）、轻量化部署的需求。

Q：什么是边缘推理
A：**边缘推理**是将训练好的 AI 模型（如 Transformer）部署在靠近用户的边缘设备（智能音箱、IoT 传感器、边缘网关等）上，直接在设备端完成数据处理、模型运算并输出结果的过程，核心是**数据不回传云端、推理本地化**。
它能解决云端推理的延迟高、隐私泄露、网络依赖等问题，同时需适配边缘设备算力有限、内存紧张、带宽不稳定的特点（如文档中 Galaxy 针对该痛点设计了协同推理方案）。

Q：TP和SP分别指什么
A：TP 和 SP 均为**模型并行（Model Parallelism）的核心技术**，具体定义如下：
	- **TP（Tensor Parallelism，张量并行）**：将 Transformer 模型的权重（如 MHA 块的 Q/K/V 权重矩阵、MLP 块的线性层权重矩阵）在多个边缘设备间划分，每个设备仅承载部分模型参数；主要用于并行化 MHA 和 MLP 块中的矩阵运算，但无法并行化 MHA 与 MLP 之间的逐元素操作（如 Dropout、Layer Norm）。
	- **SP（Sequence Parallelism，序列并行）**：沿输入数据的序列维度（如文本序列长度）对输入进行分段，让多个设备分别处理不同分段的输入；可并行化所有操作（包括逐元素操作），但要求每个设备存储完整的模型参数，对边缘设备内存压力较大。
