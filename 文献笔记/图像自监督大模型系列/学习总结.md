# MOCO
## 1.什么是对比学习。
### 原理 ：对比学习是无监督学习的一种，着重于学习同类实例之间的共同特征，区分非同类实例之间的不同之处。 
- 举个例子，从imagenet中抽出猫、猫、狗、飞机四张图，那么猫和猫的图片肯定是相似的，和狗不相似。但是和飞机比起来，猫和狗是相似的。所以对比学习就是对比着差异去学习，模型并不需要真的知道图片中代表的是什么，而只需要知道哪些图片是类似的，哪些图片是不一样的就可以了。
### 训练目的：
- 对比学习，希望相似数据（图片）最终学到的特征是相似的，在特征空间（embedding space ）中，特征向量尽量靠近；反之还希望不同的数据学到的特征向量，尽量远离。
### pretext task（代理任务）：
- 对比学习是不需要标签的（比如不需要知道图片是哪一类），但模型还是需要知道哪些图片是类似的，哪些是不相似的，才能训练。这就需要通过通过设计一些巧妙的代理任务，人为指定一些任务来实现。
### 应用最广的代理任务：instance discrimination 。
## 2.学习了对比学习框架，现阶段对比学习有三种框架：
- 一种是端到端的，比如SimCLR
- 利用memory bank的
- 最后一种就是MOCO
## 3.解决了什么
- 这种对比学习既解决了batch size无法过大的问题，利用队列算法，然而SimCLR利用其硬件优势强行把batch size拉大
- 也解决了key编码器不一致的问题：
  - 常见的key编码器比如端到端，是会随着batch来进行实时更新，很容易导致不一致
  - 而memory bank的对比学习框架，利用离线的bank来存储数据集，但由于这些特征是不同时刻的编码器得到的，所以一致性问题
  - MOCO利用动量解决了这个问题
