# 大模型从0到1系列
## 理解大模型底层架构-transformer

1. GPT上百亿的参数量，可以理解为有上百亿的词的概率<br>
2. transformer架构第一步，就是把句子或者词变成多维的